{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0vyTaRGOdmB"
      },
      "source": [
        "## Basic Structured Operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2KpLHzVOdmE"
      },
      "source": [
        "### Step 1: Initialize PySpark Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2Xue9qjMOdmE",
        "outputId": "5657c1b5-a544-4362-9219-3a4120a654b8"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"day2\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCeSCVDKOdmG"
      },
      "source": [
        "### Step 2: Load the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QHmqfHtkOdmG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Load the Chipotle dataset into a Spark DataFrame\n",
        "data_path = \"occupation.csv\"  # Replace with the actual path\n",
        "occupation = spark.read.csv(data_path, header=True, inferSchema=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8629vMtbOdmG",
        "outputId": "80bc57c1-d3d3-49d8-c2d4-7efde776ad1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- zip_code: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "occupation.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFKQzCADOdmK"
      },
      "source": [
        "### Additional questions:\n",
        "\n",
        "Use both spark SQL and Pyspark to obtain answer wherever relevant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCJtYZAHS5hi"
      },
      "source": [
        "#### Filter out rows where the age is greater than 30 and create a new DataFrame. Then, add a new column named \"is_elderly\" with a value of \"True\" for these rows and \"False\" otherwise.Rename the \"gender\" column to \"sex\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "occupation.createOrReplaceTempView(\"occupation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MPcoDeIgQ1y8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+---+-------------+--------+----------+\n",
            "|user_id|age|sex|   occupation|zip_code|is_elderly|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "|      1| 24|  M|   technician|   85711|     false|\n",
            "|      2| 53|  F|        other|   94043|      true|\n",
            "|      3| 23|  M|       writer|   32067|     false|\n",
            "|      4| 24|  M|   technician|   43537|     false|\n",
            "|      5| 33|  F|        other|   15213|      true|\n",
            "|      6| 42|  M|    executive|   98101|      true|\n",
            "|      7| 57|  M|administrator|   91344|      true|\n",
            "|      8| 36|  M|administrator|   05201|      true|\n",
            "|      9| 29|  M|      student|   01002|     false|\n",
            "|     10| 53|  M|       lawyer|   90703|      true|\n",
            "|     11| 39|  F|        other|   30329|      true|\n",
            "|     12| 28|  F|        other|   06405|     false|\n",
            "|     13| 47|  M|     educator|   29206|      true|\n",
            "|     14| 45|  M|    scientist|   55106|      true|\n",
            "|     15| 49|  F|     educator|   97301|      true|\n",
            "|     16| 21|  M|entertainment|   10309|     false|\n",
            "|     17| 30|  M|   programmer|   06355|     false|\n",
            "|     18| 35|  F|        other|   37212|      true|\n",
            "|     19| 40|  M|    librarian|   02138|      true|\n",
            "|     20| 42|  F|    homemaker|   95660|      true|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark SQL\n",
        "\n",
        "# This part of code is for the first part of question - filter out of age>30\n",
        "filtered_query = spark.sql(\"\"\"\n",
        "                select * from occupation o\n",
        "                where o.age>30\n",
        "\"\"\")\n",
        "                  \n",
        "# filtered_query.show()\n",
        "\n",
        "# This part of code is for the second part to add new column that returns true or false in is_elderly column based on age\n",
        "is_elderly_query = spark.sql(\"\"\"\n",
        "                select user_id,age,gender as sex, occupation,zip_code,\n",
        "                case\n",
        "                    when age>30 then 'true'\n",
        "                    else 'false' \n",
        "                end as is_elderly\n",
        "                from occupation\n",
        " \"\"\")\n",
        "\n",
        "is_elderly_query.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p1Mr79WeQvzS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+---+-------------+--------+----------+\n",
            "|user_id|age|sex|   occupation|zip_code|is_elderly|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "|      1| 24|  M|   technician|   85711|     false|\n",
            "|      2| 53|  F|        other|   94043|      true|\n",
            "|      3| 23|  M|       writer|   32067|     false|\n",
            "|      4| 24|  M|   technician|   43537|     false|\n",
            "|      5| 33|  F|        other|   15213|      true|\n",
            "|      6| 42|  M|    executive|   98101|      true|\n",
            "|      7| 57|  M|administrator|   91344|      true|\n",
            "|      8| 36|  M|administrator|   05201|      true|\n",
            "|      9| 29|  M|      student|   01002|     false|\n",
            "|     10| 53|  M|       lawyer|   90703|      true|\n",
            "|     11| 39|  F|        other|   30329|      true|\n",
            "|     12| 28|  F|        other|   06405|     false|\n",
            "|     13| 47|  M|     educator|   29206|      true|\n",
            "|     14| 45|  M|    scientist|   55106|      true|\n",
            "|     15| 49|  F|     educator|   97301|      true|\n",
            "|     16| 21|  M|entertainment|   10309|     false|\n",
            "|     17| 30|  M|   programmer|   06355|     false|\n",
            "|     18| 35|  F|        other|   37212|      true|\n",
            "|     19| 40|  M|    librarian|   02138|      true|\n",
            "|     20| 42|  F|    homemaker|   95660|      true|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pyspark\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "filteredd = occupation.filter(occupation.age>30)\n",
        "age_greater = occupation.withColumn(\"is_elderly\",\n",
        "    when(occupation.age>30,\"true\")\n",
        "    .otherwise(\"false\")\n",
        ").withColumnRenamed(\"gender\",'sex')\n",
        "age_greater.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoYi3_q7TCA9"
      },
      "source": [
        "#### Calculate the average age of male and female users separately. Present the result in a new DataFrame with columns \"gender\" and \"avg_age\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Seri4fe5Q2Ti"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------+\n",
            "|gender|           avg_age|\n",
            "+------+------------------+\n",
            "|     F| 33.81318681318681|\n",
            "|     M|34.149253731343286|\n",
            "+------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark SQL\n",
        "averagAgeSql = spark.sql(\"\"\"\n",
        "                select gender, avg(age) as avg_age\n",
        "                from occupation group by gender\n",
        "\"\"\")\n",
        "\n",
        "averagAgeSql.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "433nZ-6lQv5F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------+\n",
            "|gender|           avg_age|\n",
            "+------+------------------+\n",
            "|     F| 33.81318681318681|\n",
            "|     M|34.149253731343286|\n",
            "+------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pyspark\n",
        "from pyspark.sql.functions import avg\n",
        "average_age = occupation.groupBy(\"gender\").agg(avg(\"age\").alias(\"avg_age\"))\n",
        "average_age.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyMs561GTKtI"
      },
      "source": [
        "#### Add a new column named \"full_name\" to the dataset by concatenating the \"user_id\" and \"occupation\" columns. Then, rename the \"zip_code\" column to \"postal_code\" in the same DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sZc6kifIQ2qa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+-------------+-----------+---------------+\n",
            "|user_id|age|gender|   occupation|postal_code|      full_name|\n",
            "+-------+---+------+-------------+-----------+---------------+\n",
            "|      1| 24|     M|   technician|      85711|    1technician|\n",
            "|      2| 53|     F|        other|      94043|         2other|\n",
            "|      3| 23|     M|       writer|      32067|        3writer|\n",
            "|      4| 24|     M|   technician|      43537|    4technician|\n",
            "|      5| 33|     F|        other|      15213|         5other|\n",
            "|      6| 42|     M|    executive|      98101|     6executive|\n",
            "|      7| 57|     M|administrator|      91344| 7administrator|\n",
            "|      8| 36|     M|administrator|      05201| 8administrator|\n",
            "|      9| 29|     M|      student|      01002|       9student|\n",
            "|     10| 53|     M|       lawyer|      90703|       10lawyer|\n",
            "|     11| 39|     F|        other|      30329|        11other|\n",
            "|     12| 28|     F|        other|      06405|        12other|\n",
            "|     13| 47|     M|     educator|      29206|     13educator|\n",
            "|     14| 45|     M|    scientist|      55106|    14scientist|\n",
            "|     15| 49|     F|     educator|      97301|     15educator|\n",
            "|     16| 21|     M|entertainment|      10309|16entertainment|\n",
            "|     17| 30|     M|   programmer|      06355|   17programmer|\n",
            "|     18| 35|     F|        other|      37212|        18other|\n",
            "|     19| 40|     M|    librarian|      02138|    19librarian|\n",
            "|     20| 42|     F|    homemaker|      95660|    20homemaker|\n",
            "+-------+---+------+-------------+-----------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark SQL\n",
        "spark.sql(\"\"\"\n",
        "            select user_id,age,gender,occupation,zip_code as postal_code, concat(user_id,occupation) as full_name\n",
        "            from occupation\n",
        "            \"\"\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hC_1VJbnQwFI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+-------------+-----------+---------------+\n",
            "|user_id|age|gender|   occupation|postal_code|      full_name|\n",
            "+-------+---+------+-------------+-----------+---------------+\n",
            "|      1| 24|     M|   technician|      85711|    1technician|\n",
            "|      2| 53|     F|        other|      94043|         2other|\n",
            "|      3| 23|     M|       writer|      32067|        3writer|\n",
            "|      4| 24|     M|   technician|      43537|    4technician|\n",
            "|      5| 33|     F|        other|      15213|         5other|\n",
            "|      6| 42|     M|    executive|      98101|     6executive|\n",
            "|      7| 57|     M|administrator|      91344| 7administrator|\n",
            "|      8| 36|     M|administrator|      05201| 8administrator|\n",
            "|      9| 29|     M|      student|      01002|       9student|\n",
            "|     10| 53|     M|       lawyer|      90703|       10lawyer|\n",
            "|     11| 39|     F|        other|      30329|        11other|\n",
            "|     12| 28|     F|        other|      06405|        12other|\n",
            "|     13| 47|     M|     educator|      29206|     13educator|\n",
            "|     14| 45|     M|    scientist|      55106|    14scientist|\n",
            "|     15| 49|     F|     educator|      97301|     15educator|\n",
            "|     16| 21|     M|entertainment|      10309|16entertainment|\n",
            "|     17| 30|     M|   programmer|      06355|   17programmer|\n",
            "|     18| 35|     F|        other|      37212|        18other|\n",
            "|     19| 40|     M|    librarian|      02138|    19librarian|\n",
            "|     20| 42|     F|    homemaker|      95660|    20homemaker|\n",
            "+-------+---+------+-------------+-----------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pyspark\n",
        "from pyspark.sql.functions import col,concat\n",
        "\n",
        "full_name_question = occupation.withColumn(\"full_name\",concat(col(\"user_id\"),col(\"occupation\"))).withColumnRenamed(\"zip_code\",\"postal_code\")\n",
        "full_name_question.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CPDOqPZUTWd"
      },
      "source": [
        "#### Filter out rows where occupation is 'technician', select only the \"user_id\" and \"age\" columns, and then add a new column \"age_diff\" that calculates the difference between the user's age and the average age in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "K8-rf3eAUZ0q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------------------+\n",
            "|user_id|age|          age_diff|\n",
            "+-------+---+------------------+\n",
            "|      1| 24|-10.05196182396607|\n",
            "|      4| 24|-10.05196182396607|\n",
            "|     44| 26| -8.05196182396607|\n",
            "|     77| 30| -4.05196182396607|\n",
            "|    143| 42|  7.94803817603393|\n",
            "|    197| 55| 20.94803817603393|\n",
            "|    244| 28| -6.05196182396607|\n",
            "|    294| 34| -0.05196182396607|\n",
            "|    311| 32| -2.05196182396607|\n",
            "|    325| 48| 13.94803817603393|\n",
            "|    441| 50| 15.94803817603393|\n",
            "|    456| 24|-10.05196182396607|\n",
            "|    458| 47| 12.94803817603393|\n",
            "|    488| 48| 13.94803817603393|\n",
            "|    545| 27| -7.05196182396607|\n",
            "|    670| 30| -4.05196182396607|\n",
            "|    715| 21|-13.05196182396607|\n",
            "|    717| 24|-10.05196182396607|\n",
            "|    718| 42|  7.94803817603393|\n",
            "|    738| 35|  0.94803817603393|\n",
            "+-------+---+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark SQL\n",
        "average_age = spark.sql(\"SELECT AVG(age) AS avg_age FROM occupation\").collect()[0][\"avg_age\"]\n",
        "\n",
        "spark.sql(\"SELECT user_id, age, age - {} AS age_diff FROM occupation WHERE occupation = 'technician'\"\n",
        "          .format(average_age)) \\\n",
        "    .show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-HJ1PEFNUbg0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+-------------------+\n",
            "|user_id|age|           age_diff|\n",
            "+-------+---+-------------------+\n",
            "|      1| 24|-10.051961823966067|\n",
            "|      4| 24|-10.051961823966067|\n",
            "|     44| 26| -8.051961823966067|\n",
            "|     77| 30| -4.051961823966067|\n",
            "|    143| 42|  7.948038176033933|\n",
            "|    197| 55| 20.948038176033933|\n",
            "|    244| 28| -6.051961823966067|\n",
            "|    294| 34|-0.0519618239660673|\n",
            "|    311| 32|-2.0519618239660673|\n",
            "|    325| 48| 13.948038176033933|\n",
            "|    441| 50| 15.948038176033933|\n",
            "|    456| 24|-10.051961823966067|\n",
            "|    458| 47| 12.948038176033933|\n",
            "|    488| 48| 13.948038176033933|\n",
            "|    545| 27| -7.051961823966067|\n",
            "|    670| 30| -4.051961823966067|\n",
            "|    715| 21|-13.051961823966067|\n",
            "|    717| 24|-10.051961823966067|\n",
            "|    718| 42|  7.948038176033933|\n",
            "|    738| 35| 0.9480381760339327|\n",
            "+-------+---+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pyspark\n",
        "average_age = occupation.select(avg(\"age\")).collect()[0][0]\n",
        "\n",
        "age_diff_df = occupation.filter(col(\"occupation\") == \"technician\") \\\n",
        "                       .select(\"user_id\", \"age\") \\\n",
        "                       .withColumn(\"age_diff\", col(\"age\") - average_age)\n",
        "\n",
        "age_diff_df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTIR2tJuTRID"
      },
      "source": [
        "#### Divide the dataset into two DataFrames: one with male users and another with female users. Repartition both DataFrames to have 2 partitions each. Then, union these two DataFrames together and display the resulting DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4JKAn2n0P6Ib"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+----------+--------+\n",
            "|user_id|age|gender|occupation|zip_code|\n",
            "+-------+---+------+----------+--------+\n",
            "|    896| 28|     M|    writer|   91505|\n",
            "|    156| 25|     M|  educator|   08360|\n",
            "|    568| 39|     M|  educator|   01915|\n",
            "|    624| 19|     M|   student|   30067|\n",
            "|    832| 24|     M|technician|   77042|\n",
            "|    684| 28|     M|   student|   55414|\n",
            "|    905| 27|     M|     other|   30350|\n",
            "|    148| 33|     M|  engineer|   97006|\n",
            "|    313| 41|     M| marketing|   60035|\n",
            "|    478| 29|     M|     other|   10019|\n",
            "|    332| 20|     M|   student|   40504|\n",
            "|    492| 57|     M|  educator|   94618|\n",
            "|    833| 34|     M|    writer|   90019|\n",
            "|    470| 24|     M|programmer|   10021|\n",
            "|     21| 26|     M|    writer|   30068|\n",
            "|    265| 26|     M| executive|   84601|\n",
            "|     33| 23|     M|   student|   27510|\n",
            "|    133| 53|     M|  engineer|   78602|\n",
            "|    682| 23|     M|programmer|   55128|\n",
            "|    650| 42|     M|  engineer|   83814|\n",
            "+-------+---+------+----------+--------+\n",
            "only showing top 20 rows\n",
            "\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "male_df = spark.sql(\"\"\"\n",
        "                    select * from occupation\n",
        "                    where gender = \"M\"\n",
        "                     \"\"\").repartition(2)\n",
        "                \n",
        "male_df.show()\n",
        "num_partitions = male_df.rdd.getNumPartitions()\n",
        "print(num_partitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+-------------+--------+\n",
            "|user_id|age|gender|   occupation|zip_code|\n",
            "+-------+---+------+-------------+--------+\n",
            "|    505| 27|     F|        other|   20657|\n",
            "|    241| 26|     F|      student|   20001|\n",
            "|    629| 46|     F|        other|   44224|\n",
            "|    482| 18|     F|      student|   40256|\n",
            "|    304| 22|     F|      student|   71701|\n",
            "|    147| 40|     F|    librarian|   02143|\n",
            "|    354| 29|     F|    librarian|   48197|\n",
            "|    588| 18|     F|      student|   93063|\n",
            "|    175| 26|     F|    scientist|   21911|\n",
            "|    490| 29|     F|       artist|   V5A2B|\n",
            "|    457| 33|     F|     salesman|   30011|\n",
            "|    165| 20|     F|        other|   53715|\n",
            "|    342| 25|     F|        other|   98006|\n",
            "|    401| 46|     F|   healthcare|   84107|\n",
            "|    681| 44|     F|    marketing|   97208|\n",
            "|    238| 42|     F|administrator|   44124|\n",
            "|     52| 18|     F|      student|   55105|\n",
            "|    556| 35|     F|     educator|   30606|\n",
            "|    485| 44|     F|     educator|   95821|\n",
            "|    126| 28|     F|       lawyer|   20015|\n",
            "+-------+---+------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "female_df = spark.sql(\"\"\"\n",
        "                    select * from occupation\n",
        "                    where gender = \"F\"\n",
        "                     \"\"\").repartition(2)\n",
        "                \n",
        "female_df.show()\n",
        "num_partitions = female_df.rdd.getNumPartitions()\n",
        "print(num_partitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+----------+--------+\n",
            "|user_id|age|gender|occupation|zip_code|\n",
            "+-------+---+------+----------+--------+\n",
            "|    896| 28|     M|    writer|   91505|\n",
            "|    156| 25|     M|  educator|   08360|\n",
            "|    568| 39|     M|  educator|   01915|\n",
            "|    624| 19|     M|   student|   30067|\n",
            "|    832| 24|     M|technician|   77042|\n",
            "|    684| 28|     M|   student|   55414|\n",
            "|    905| 27|     M|     other|   30350|\n",
            "|    148| 33|     M|  engineer|   97006|\n",
            "|    313| 41|     M| marketing|   60035|\n",
            "|    478| 29|     M|     other|   10019|\n",
            "|    332| 20|     M|   student|   40504|\n",
            "|    492| 57|     M|  educator|   94618|\n",
            "|    833| 34|     M|    writer|   90019|\n",
            "|    470| 24|     M|programmer|   10021|\n",
            "|     21| 26|     M|    writer|   30068|\n",
            "|    265| 26|     M| executive|   84601|\n",
            "|     33| 23|     M|   student|   27510|\n",
            "|    133| 53|     M|  engineer|   78602|\n",
            "|    682| 23|     M|programmer|   55128|\n",
            "|    650| 42|     M|  engineer|   83814|\n",
            "+-------+---+------+----------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "resulting_df = male_df.union(female_df)\n",
        "resulting_df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfVdjYOcTn_g"
      },
      "source": [
        "#### Create and fill a new DataFrame named user_ratings with columns user_id and rating max 10 column. Both user_data and user_ratings share the user_id column. Combine these two DataFrames to create a new DataFrame that includes user information and their corresponding ratings. Make sure to keep only the users present in both DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "a3Jw-vaEP4U4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|user_id|  name|\n",
            "+-------+------+\n",
            "|      1| Rahul|\n",
            "|      2| Priya|\n",
            "|      3|  Amit|\n",
            "|      4|  Neha|\n",
            "|      5|Rajesh|\n",
            "|      6| Sneha|\n",
            "|      7|  Arun|\n",
            "|      8|Anjali|\n",
            "|      9|Vikram|\n",
            "|     10| Swati|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Indian user data\n",
        "user_data = [\n",
        "    (1, \"Rahul\"),\n",
        "    (2, \"Priya\"),\n",
        "    (3, \"Amit\"),\n",
        "    (4, \"Neha\"),\n",
        "    (5, \"Rajesh\"),\n",
        "    (6, \"Sneha\"),\n",
        "    (7, \"Arun\"),\n",
        "    (8, \"Anjali\"),\n",
        "    (9, \"Vikram\"),\n",
        "    (10, \"Swati\")\n",
        "]\n",
        "\n",
        "# Defining the schema for Indian user data DataFrame\n",
        "user_schema = [\"user_id\", \"name\"]\n",
        "\n",
        "# Create the Indian user data DataFrame\n",
        "user_data_df = spark.createDataFrame(user_data,user_schema)\n",
        "\n",
        "# Show the Indian user data DataFrame\n",
        "user_data_df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|user_id|rating|\n",
            "+-------+------+\n",
            "|      1|     9|\n",
            "|      2|     8|\n",
            "|      3|    10|\n",
            "|      4|     7|\n",
            "|      5|     9|\n",
            "|      6|     6|\n",
            "|      7|    10|\n",
            "|      8|     8|\n",
            "|      9|     7|\n",
            "|     10|     9|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_ratings_data = [\n",
        "    (1, 9),\n",
        "    (2, 8),\n",
        "    (3, 10),\n",
        "    (4, 7),\n",
        "    (5, 9),\n",
        "    (6, 6),\n",
        "    (7, 10),\n",
        "    (8, 8),\n",
        "    (9, 7),\n",
        "    (10, 9)\n",
        "]\n",
        "\n",
        "# Define the schema for user_ratings DataFrame\n",
        "user_ratings_schema = [\"user_id\", \"rating\"]\n",
        "\n",
        "# Create the user_ratings DataFrame\n",
        "user_ratings = spark.createDataFrame(user_ratings_data, user_ratings_schema)\n",
        "\n",
        "# Select relevant columns from \"user_ratings\"\n",
        "user_ratings.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 71:=============================>                            (4 + 4) / 8]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+------+\n",
            "|user_id|  name|rating|\n",
            "+-------+------+------+\n",
            "|      1| Rahul|     9|\n",
            "|      2| Priya|     8|\n",
            "|      3|  Amit|    10|\n",
            "|      4|  Neha|     7|\n",
            "|      5|Rajesh|     9|\n",
            "|      6| Sneha|     6|\n",
            "|      7|  Arun|    10|\n",
            "|      8|Anjali|     8|\n",
            "|      9|Vikram|     7|\n",
            "|     10| Swati|     9|\n",
            "+-------+------+------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "combined_df = user_data_df.join(user_ratings, on=\"user_id\")\n",
        "\n",
        "combined_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DQ",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
